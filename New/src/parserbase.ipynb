{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "from typing import Optional, Union, List, Callable\n",
    "from dataclasses import dataclass, make_dataclass, field\n",
    "\n",
    "PKG_ROOT = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "if not PKG_ROOT in sys.path:\n",
    "    sys.path.append(PKG_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_names_old(name:str, df:pd.DataFrame):\n",
    "    '''\n",
    "    Construct dataclass or nested dataclass from a dataframe\n",
    "    '''\n",
    "    if df.shape[1] == 2:\n",
    "        data = [(_[1], str, field(default=_[0])) for _ in df.values]\n",
    "        return make_dataclass(name, data)\n",
    "    else:\n",
    "        group = df.groupby(df.columns[0])\n",
    "        data = [(k, dataclass, field(default=make_names_old(k, v.drop(v.columns[0], axis=1)))) for k, v in group]\n",
    "        return make_dataclass(name, data)\n",
    "\n",
    "def make_names_(name:str, df:pd.DataFrame):\n",
    "    '''\n",
    "    Construct dataclass or nested dataclass from a dataframe\n",
    "    '''\n",
    "    if df.shape[1] == 2:\n",
    "        data = [(_[1], str, field(default=_[0])) for _ in df.values]\n",
    "        return make_dataclass(name, data)\n",
    "    else:\n",
    "        group = df.groupby(df.columns[0])\n",
    "        if group.ngroups == 1:\n",
    "            return make_names_(name, df.drop(df.columns[0], axis=1))\n",
    "        data = [(k, dataclass, field(default=make_names_(k, v.drop(v.columns[0], axis=1)))) for k, v in group]\n",
    "        return make_dataclass(name, data)\n",
    "    \n",
    "def make_names(name:str, df:pd.DataFrame, ignore_cols:List=[]):\n",
    "    return make_names_(name=name, df=df[[_ for _ in df.columns if not _ in ignore_cols]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_duplicates(df:pd.DataFrame, groupby:Optional[Union[List, str]]=None):\n",
    "    if groupby is None:\n",
    "        col = df.columns[-1]\n",
    "        df = df.groupby(col).apply(lambda x: x.reset_index())\n",
    "        if df.index.nlevels > 1:\n",
    "            df = df.droplevel(0)\n",
    "        df[col] = df.apply(lambda x: f'{re.sub(\"_+\", \"_\", x[col])}{(\"_\" + str(x.name)) if x.name > 0 else \"\"}', axis=1)\n",
    "        return df.reset_index(drop=True).drop('index', axis=1)\n",
    "    else:\n",
    "        return df.groupby(groupby).apply(clean_duplicates).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlockBase:\n",
    "    \n",
    "    @staticmethod\n",
    "    def bytes2Num(barray:bytes, signed:bool=False, order:str='little'):\n",
    "        return int.from_bytes(barray, signed=signed, byteorder=order)\n",
    "    \n",
    "    @staticmethod\n",
    "    def num2Bytes(num:int, length:int, signed=False, order='little'):\n",
    "        return num.to_bytes(length, signed=signed, byteorder=order)\n",
    "    \n",
    "    @staticmethod\n",
    "    def to_int(num:float):\n",
    "        '''\n",
    "        Integer will be coerced to float if np.nan exists in the same column\n",
    "        Force the value to int, if np.nan then return np.nan\n",
    "        '''\n",
    "        if isinstance(num, str): #0x0000 in dataframe\n",
    "            return int(num, 16)\n",
    "        if num == None:\n",
    "            return None\n",
    "        if np.isnan(num):\n",
    "            return None\n",
    "        return int(num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ValueBlock(BlockBase):\n",
    "    \n",
    "    def __init__(self\n",
    "                 ,pbuffer: bytearray  #contents of parent segment\n",
    "                 ,valueLoc: int\n",
    "                 ,size: int\n",
    "                 ,signed: bool = False\n",
    "                 ,order: str = 'little'\n",
    "                 ,optimize: Optional[int] = None\n",
    "                 ,skiphead: int = 0\n",
    "                 ,skiptail: int = 0):\n",
    "        self.pbuffer = pbuffer\n",
    "        self.valueLoc = self.to_int(valueLoc)\n",
    "        self.size = self.to_int(size)\n",
    "        self.signed = signed\n",
    "        self.order = order\n",
    "        self.optimize = self.to_int(optimize)\n",
    "        self.skiphead = skiphead\n",
    "        self.skiptail = skiptail\n",
    "        self.notVoid = self.not_void()\n",
    "    \n",
    "    def not_void(self):\n",
    "        if any([pd.isnull(self.valueLoc), pd.isnull(self.size)]):\n",
    "            return False\n",
    "        if any([self.pbuffer is None\n",
    "                ,len(self.pbuffer)==0\n",
    "                ,self.valueLoc < 0\n",
    "                ,self.size <= 0\n",
    "                ,self.valueLoc + self.size > len(self.pbuffer)]):\n",
    "            return False\n",
    "        return True\n",
    "     \n",
    "    @property\n",
    "    def bytes(self):\n",
    "        return self.pbuffer[self.valueLoc+self.skiphead\n",
    "                           :self.valueLoc+self.size+self.skiphead-self.skiptail]\n",
    "        \n",
    "    @property\n",
    "    def value(self):\n",
    "        return self.bytes2Num(self.bytes, self.signed, self.order)\n",
    "    \n",
    "    @property\n",
    "    def string(self):\n",
    "        s = self.bytes\n",
    "        p = np.argmax(np.logical_and(np.array(s) > 127\n",
    "                                     ,np.array(s) < 32))\n",
    "        return str(s[:p], encoding='latin')\n",
    "    \n",
    "    def set_value(self, value:Union[int, Enum]):\n",
    "        if hasattr(value, 'value'):\n",
    "            value = value.value\n",
    "        self.pbuffer[self.valueLoc+self.skiphead\n",
    "                   :self.valueLoc+self.skiphead-self.skiptail] = self.num2Bytes(value, self.size, self.signed, self.order) \n",
    "            \n",
    "    def inc_value(self, inc_value:int=1):\n",
    "        self.set_value(self.value + inc_value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableBlock(BlockBase):\n",
    "    '''\n",
    "    Create ValueBlock that using a table of values to fill\n",
    "    refTable includes Kit, Race, Class, Gender, Alignment and RacialEnemy defined in CRETABLE.csv file\n",
    "    '''\n",
    "    \n",
    "    def __init__(self\n",
    "                ,pbuffer: bytearray\n",
    "                ,valueLoc: int\n",
    "                ,size: int\n",
    "                ,signed: bool\n",
    "                ,order: str\n",
    "                ,refTableName: pd.DataFrame\n",
    "                ,optimize: Optional[int]\n",
    "                ,refTable: pd.DataFrame):\n",
    "        self.pbuffer = pbuffer\n",
    "        self.valueLoc = self.to_int(valueLoc)\n",
    "        self.size = self.to_int(size)\n",
    "        self.signed = signed\n",
    "        self.order = order\n",
    "        self.refTable = refTable\n",
    "        self.optimize = self.to_int(optimize)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegBlock(BlockBase):\n",
    "    '''\n",
    "    Parse subStructures as defined in GAMSEGS.csv and CRESEGS.csv\n",
    "    '''\n",
    "    \n",
    "    def __init__(self\n",
    "                ,resourceDir: str\n",
    "                ,pbuffer: bytearray\n",
    "                ,CREIndexLength: int\n",
    "                ,CREOffsetLoc: int\n",
    "                ,CRESizeLoc: int\n",
    "                ,name: str\n",
    "                ,countLoc: int  #offset pointer to buffer\n",
    "                ,offsetLoc: int  #count pointer to buffer\n",
    "                ,sizeLoc: int\n",
    "                ,sizeValue: Optional[int] = None\n",
    "                ,countValue: Optional[int] = None\n",
    "                ,offsetValue: Optional[int] = None):  #only the header segment has no offset value\n",
    "        self.resourceDir = resourceDir\n",
    "        self.name = name\n",
    "        self.pbuffer = pbuffer\n",
    "        self.CREIndexLength = self.to_int(CREIndexLength)\n",
    "        self.CREOffsetLoc = self.to_int(CREOffsetLoc)\n",
    "        self.CRESizeLoc = self.to_int(CRESizeLoc)\n",
    "        self.countLoc = self.to_int(countLoc)\n",
    "        self.offsetLoc = self.to_int(offsetLoc)\n",
    "        self.sizeLoc = self.to_int(sizeLoc)\n",
    "        self.sizeValue = self.to_int(sizeValue)\n",
    "        self.countValue = self.to_int(countValue)\n",
    "        self.offsetValue = self.to_int(offsetValue)\n",
    "        self.offsetBlock = ValueBlock(self.pbuffer, self.offsetLoc, 4)\n",
    "        self.countBlock = ValueBlock(self.pbuffer, self.countLoc, 4)\n",
    "        self.sizeBlock = ValueBlock(self.pbuffer, self.sizeLoc, 4)\n",
    "        self.buffer = self.pbuffer[self.offsetValue: self.offsetValue + self.sizeValue]\n",
    "        if name.upper() in ['PARTY', 'NPC']:\n",
    "            self.parseParty()\n",
    "            \n",
    "    \n",
    "    def parseParty(self):\n",
    "        self.indexHeader = self.buffer[: self.CREIndexLength * self.countBlock.value]\n",
    "        self.CREOffsets = [ValueBlock(self.buffer, self.CREOffsetLoc + self.CREIndexLength * i, 4) for i in range(self.countBlock.value)]\n",
    "        self.CRESizes = [ValueBlock(self.buffer, self.CRESizeLoc + self.CREIndexLength * i, 4) for i in range(self.countBlock.value)]\n",
    "        vRecords = pd.read_csv(os.path.join(self.resourceDir, 'CREVALUES.csv'), index_col=0)\n",
    "        tRecords = pd.read_csv(os.path.join(self.resourceDir, 'CRETABLES.csv'), index_col=0)\n",
    "        sRecords = pd.read_csv(os.path.join(self.resourceDir, 'CRESEGS.csv'), index_col=0)\n",
    "        self.CRES = [GamCreBase(self.resourceDir\n",
    "                                ,self.pbuffer[o.value: o.value + s.value]\n",
    "                                ,vRecords\n",
    "                                ,tRecords\n",
    "                                ,sRecords\n",
    "                                ,o\n",
    "                                ,s) for o, s in zip(self.CREOffsets, self.CRESizes)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GamCreBase(BlockBase):\n",
    "    \n",
    "    \n",
    "    def __init__(self\n",
    "                ,resourceDir:str\n",
    "                ,buffer: bytes = b''\n",
    "                ,valueRecords: pd.DataFrame = pd.DataFrame([], columns=pd.Index(['Name', 'ValueLoc', 'Size', 'Signed', 'Order', 'Optimize']))\n",
    "                ,tableRecords: pd.DataFrame = pd.DataFrame([], columns=pd.Index(['Name', 'ValueLoc', 'Size', 'Signed', 'Order', 'RefTable', 'Optimize']))\n",
    "                ,segRecords: pd.DataFrame = pd.DataFrame([], columns=pd.Index(['SubSegs', 'CountLoc', 'OffsetLoc', 'SizeLoc', 'SizeValue', 'CountValue']))\n",
    "                ,offsetBlock: Optional[ValueBlock] = None #CRE has reference in the Party/NPC segment\n",
    "                ,sizeBlokc: Optional[ValueBlock] = None #CRE has reference in the Party/NPC segment\n",
    "                ):\n",
    "        self.resourceDir = resourceDir\n",
    "        self.buffer = buffer\n",
    "        self.bufferSize = len(self.buffer)\n",
    "        self.valueRecords = valueRecords\n",
    "        self.tableRecords = tableRecords\n",
    "        self.segRecords = segRecords\n",
    "        self.VALUES = make_dataclass('SEGS', [])\n",
    "        self.TABLES = make_dataclass('SEGS', [])\n",
    "        self.SEGS = pd.Series([], dtype=object)\n",
    "        self.CRELocs = self.get_CRE_locs()\n",
    "        self.initiate_seg_size()\n",
    "        self.init_values()\n",
    "        self.init_tables()\n",
    "        self.init_segs()\n",
    "           \n",
    "        \n",
    "    def initiate_seg_size(self):\n",
    "        '''\n",
    "        Retrieve offsets of each segment from segRecords to determine the size of each seg, \n",
    "        Write back into the SizeValue column\n",
    "        And reset_index to ensure they are aligned in the right packing sequence\n",
    "        '''\n",
    "        offsets = self.segRecords[self.segRecords['OffsetLoc'].notnull()]\n",
    "        offsets = offsets['OffsetLoc'].apply(lambda x: self.bytes2Num(self.buffer[self.to_int(x)\n",
    "                                                                                 :self.to_int(x) + 4])).sort_values()\n",
    "        nonZeroOffsets = pd.concat([pd.Series([0]), offsets[offsets!=0]])\n",
    "        nonZeroOffsets[nonZeroOffsets > self.bufferSize] = self.bufferSize\n",
    "        lengths = pd.concat([offsets[offsets==0], nonZeroOffsets.shift(-1, fill_value=self.bufferSize) - nonZeroOffsets])\n",
    "        self.segRecords.update(lengths.sort_index().rename('SizeValue').to_frame())\n",
    "        self.segRecords = self.segRecords.join(offsets.rename('OffsetValue').to_frame()).fillna(value={'OffsetValue': 0})\n",
    "        \n",
    "        \n",
    "    def bind_tables(self):\n",
    "        '''\n",
    "        Covert the RefTable column in the tableRecords df into real dataframe\n",
    "        '''\n",
    "        if not self.tableRecords.empty:\n",
    "            self.tableRecords['RefTable'] = self.tableRecords['RefTable'].apply(lambda x: pd.read_csv(os.path.join(self.resourceDir, x + '.csv')))\n",
    "        \n",
    "    def get_CRE_locs(self):\n",
    "        loc_df = pd.read_csv(os.path.join(self.resourceDir, 'CRELOC.csv'), index_col=0)\n",
    "        CREIndexLen = loc_df[loc_df['SubSegs']=='Header']['SizeValue'].iloc[0]\n",
    "        CREOffsetLoc, CRESizeLoc =  loc_df[loc_df['SubSegs']=='CRE'][['OffsetLoc', 'SizeLoc']].iloc[0].apply(self.to_int)\n",
    "        return CREIndexLen, CREOffsetLoc, CRESizeLoc\n",
    "        \n",
    "    \n",
    "    def init_values(self, buffer:Optional[bytearray]=None): \n",
    "        if not self.valueRecords.empty:\n",
    "            if buffer == None:\n",
    "                buffer = self.buffer\n",
    "            self.VALUES = make_dataclass('VALUES', self.valueRecords.apply(lambda x: (x[0]\n",
    "                                                                                     ,ValueBlock\n",
    "                                                                                     ,ValueBlock(buffer, *x[1:]))\n",
    "                                                                           ,axis=1))\n",
    "            \n",
    "    def init_tables(self, buffer:Optional[bytearray]=None):\n",
    "        if not self.tableRecords.empty:\n",
    "            if buffer == None:\n",
    "                buffer = self.buffer\n",
    "            self.TABLES = make_dataclass('TABLES', self.tableRecords.apply(lambda x: (x[0]\n",
    "                                                                                     ,TableBlock\n",
    "                                                                                     ,TableBlock(buffer\n",
    "                                                                                                 ,*x[1:]\n",
    "                                                                                                 ,pd.read_csv(os.path.join(self.resourceDir\n",
    "                                                                                                                           ,x['RefTable']+'.csv')\n",
    "                                                                                                              ,index_col=0)))\n",
    "                                                                           ,axis=1))\n",
    "            \n",
    "    def init_segs(self, buffer:Optional[bytearray]=None):\n",
    "        '''\n",
    "        Need to keep sequence order\n",
    "        So use pd.Series instead of dataclass\n",
    "        '''\n",
    "        if not self.segRecords.empty:\n",
    "            if buffer == None:\n",
    "                buffer = self.buffer\n",
    "            self.SEGS = (self.segRecords\n",
    "                         .set_index(self.segRecords.columns[0])\n",
    "                         .apply(lambda x: SegBlock(self.resourceDir, buffer, *self.CRELocs, x.name, *x), axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "616803b2f19e1e9bcbf5ac8abb36b7fd12ef6319f5b436273684431f9aa2d3e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
