{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import zipfile\n",
    "from typing import Optional, Union, List, Callable, Dict, Tuple\n",
    "from dataclasses import dataclass, make_dataclass, field\n",
    "from abc import ABC\n",
    "from importnb import Notebook\n",
    "\n",
    "PKG_ROOT = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "if not PKG_ROOT in sys.path:\n",
    "    sys.path.append(PKG_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Notebook():\n",
    "    from src.basestructs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordBase(BlockBase):\n",
    "     \n",
    "    def __init__(self, segList:List, nameMap: Optional[Dict]=None, template:Optional[bytearray]=None):\n",
    "        '''\n",
    "        SegList has the format of [(name, length, datatype)]\n",
    "        datatype includes: name, which will be mapped to codes in nameMap\n",
    "                           int\n",
    "                           str\n",
    "                           None\n",
    "        '''\n",
    "        self.pattern = re.compile(b''.join([f'(?P<{n}>.{{{s}}})'.encode() for (n, s, t) in segList]))\n",
    "        self.names, self.sizes, self.dtypes = zip(*segList)\n",
    "        self.sizes = np.array(self.sizes)\n",
    "        self.sizeMap = dict(zip(self.names, self.sizes))\n",
    "        self.rangeMap = dict([(n, r) for (n, r) in zip(self.names, [range(*_) for _ in zip(np.concatenate([[0], self.sizes.cumsum()])\n",
    "                                                                                           ,self.sizes.cumsum())])])\n",
    "        self.typeMap = dict(zip(self.names, self.dtypes))\n",
    "        self.size = self.sizes.sum()\n",
    "        self.nameMap = nameMap\n",
    "        if template is None:\n",
    "            self.template = bytearray(b'0' * self.size)\n",
    "        else:\n",
    "            self.template = template\n",
    "            \n",
    "            \n",
    "    def parse(self, buffer:bytearray):\n",
    "        return pd.DataFrame(_.groupdict() for _ in self.pattern.finditer(buffer))\n",
    "    \n",
    "    def infer_col(self, col:pd.Series):\n",
    "        dtype = self.typeMap.get(col.name, None)\n",
    "        if dtype is None or dtype == 'NAME':\n",
    "            return col\n",
    "        if dtype == int:\n",
    "            return col.apply(self.bytes2Num)\n",
    "        if dtype == str:\n",
    "            return col.apply(self.bytes2Str)\n",
    "        if dtype.upper() == 'INTNAME':\n",
    "            return col.apply(lambda x: self.nameMap(self.bytes2Num(x)).name)\n",
    "        if dtype.upper() == 'STRNAME':\n",
    "            return col.apply(lambda x: self.nameMap(self.bytes2Str(x)).name)\n",
    "        if dtype.upper() == 'BYTES':\n",
    "            return col.apply(lambda x: x.decode('latin'))\n",
    "        \n",
    "        \n",
    "    def inverse_infer_col(self, col:pd.Series):\n",
    "        col = col.apply(lambda x: x.name if hasattr(x, 'name') else x)\n",
    "        dtype = self.typeMap.get(col.name, None)\n",
    "        size = self.sizeMap.get(col.name)\n",
    "        if dtype is None or dtype == 'NAME':\n",
    "            return col\n",
    "        if dtype == int:\n",
    "            return col.apply(lambda x: self.num2Bytes(x, size))\n",
    "        if dtype == str:\n",
    "            return col.apply(lambda x: x.encode().ljust(size, b'\\x00'))\n",
    "        if dtype.upper() == 'INTNAME':\n",
    "            return col.apply(lambda x: self.num2Bytes(getattr(self.nameMap, x).value, size))\n",
    "        if dtype.upper() == 'STRNAME':\n",
    "            return col.apply(lambda x: getattr(self.nameMap, x).value.encode().ljust(size, b'\\x00'))\n",
    "        if dtype.upper() == 'BYTES':\n",
    "            return col.apply(lambda x: x.encode('latin'))\n",
    "            \n",
    "    \n",
    "    def infer(self, df:pd.DataFrame):\n",
    "        return pd.concat([self.infer_col(col) for name, col in df.iteritems()], axis=1)\n",
    "    \n",
    "    def inverse_infer(self, df:pd.DataFrame):\n",
    "        return pd.concat([self.inverse_infer_col(col) for name, col in df.iteritems()], axis=1)\n",
    "    \n",
    "    def make_records(self, values:pd.DataFrame, repeatCol:int=-1):\n",
    "        '''\n",
    "        @params values is a dataframe with the last column as the repeats of each row\n",
    "        ColNames has to match the segment names in the pattern\n",
    "        '''\n",
    "        if repeatCol is not None:\n",
    "            df = values.groupby(values.columns[repeatCol]).apply(lambda x: pd.concat([x] * x.name)).reset_index(drop=True).drop(values.columns[repeatCol], axis=1)\n",
    "        else:\n",
    "            df = values\n",
    "        temp_df = pd.DataFrame([self.pattern.search(self.template).groupdict()] * df.shape[0])\n",
    "        temp_df.update(df)\n",
    "        return temp_df\n",
    "\n",
    "    def make_recordIndex_from_dict(self, values:List[pd.Series], repeats:Optional[Union[int, Tuple, List, np.ndarray]]=1):\n",
    "        values = [pd.Series(v, name=k) for k, v in values.items()]\n",
    "        repeats = np.array(repeats).ravel()\n",
    "        if repeats.size == 1:\n",
    "            repeats = np.tile(repeats, values[0].size)\n",
    "        df = pd.DataFrame(values).T\n",
    "        df = df[[_ for _ in self.names if _ in df.columns]] # make sure the sequence is aligned with pattern segment sequence\n",
    "        df.insert(df.shape[1], 'REPEATS', repeats)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TableBlock(ValueBlock):\n",
    "    '''\n",
    "    Create ValueBlock that using a table of values to fill\n",
    "    refTable includes Kit, Race, Class, Gender, Alignment and RacialEnemy defined in CRETABLE.csv file\n",
    "    '''\n",
    "    \n",
    "    def __init__(self\n",
    "                ,pbuffer: bytearray\n",
    "                ,name: str\n",
    "                ,valueLoc: int\n",
    "                ,size: int\n",
    "                ,signed: bool\n",
    "                ,order: str\n",
    "                ,refTableName: str\n",
    "                ,optimize: Optional[int]\n",
    "                ,refTable: Enum):\n",
    "        super().__init__(pbuffer, name, valueLoc, size, signed, order, optimize)\n",
    "        self.refTable = refTable\n",
    "        \n",
    "        \n",
    "    def inc_value(self, inc_value:int=1):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def value(self):\n",
    "        v = super().value\n",
    "        if v is not None:\n",
    "            return self.refTable(v).name\n",
    "        return None\n",
    "    \n",
    "    def set_value(self, value:Union[int, Enum, str]):\n",
    "        if isinstance(value, str):\n",
    "            for k, v in self.refTable.__members__.items():\n",
    "                if value.upper() == k:\n",
    "                    value = v.value\n",
    "                    break\n",
    "            else:\n",
    "                value = None\n",
    "        super().set_value(value) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegBlock(BlockBase):\n",
    "    '''\n",
    "    Base class of subStructures as defined in GAMSEGS.csv and CRESEGS.csv\n",
    "    Used for dummy subStructures that will not be modified\n",
    "    '''\n",
    "    \n",
    "    def __init__(self\n",
    "                ,savRef: object\n",
    "                ,parentRef: object\n",
    "                ,pbuffer: bytearray\n",
    "                ,name: str\n",
    "                ,countLoc: int  #offset pointer to buffer\n",
    "                ,offsetLoc: int  #count pointer to buffer\n",
    "                ,sizeLoc: int\n",
    "                ,sizeValue: Optional[int] = None\n",
    "                ,countValue: Optional[int] = None\n",
    "                ,offsetValue: Optional[int] = None):  #only the header segment has no offset value\n",
    "        self.savRef = savRef\n",
    "        self.parentRef = parentRef\n",
    "        self.resourceDir = savRef.resourceDir\n",
    "        self.name = name\n",
    "        self.pbuffer = pbuffer\n",
    "        self.sizeValue = self.to_int(sizeValue)\n",
    "        self.countValue = self.to_int(countValue)\n",
    "        self.offsetValue = self.to_int(offsetValue)\n",
    "        self.offsetBlock = ValueBlock(self.pbuffer, 'OFFSET', self.to_int(offsetLoc), 4)\n",
    "        self.countBlock = ValueBlock(self.pbuffer, 'COUNT', self.to_int(countLoc), 4)\n",
    "        self.sizeBlock = ValueBlock(self.pbuffer, 'SIZE', self.to_int(sizeLoc), 4)\n",
    "        self.buffer = self.pbuffer[self.offsetValue: self.offsetValue + self.sizeValue]\n",
    "        self.previous = None\n",
    "\n",
    "            \n",
    "    def pack(self):\n",
    "        self.sizeValue = len(self.buffer)\n",
    "        if self.previous is not None:\n",
    "            self.offsetValue = self.previous.offsetValue + self.previous.sizeValue\n",
    "        return self.buffer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecordsBlock(SegBlock):\n",
    "    '''\n",
    "    Parse subStructures in CRE files that's composed of a list of records\n",
    "    including spell, item, effect, and item\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.countValue = self.countBlock.value\n",
    "        self.df = self.Pattern.parse(self.buffer)\n",
    "        \n",
    "    @property\n",
    "    def display(self):\n",
    "        return self.Pattern.infer(self.df)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        display(self.display)\n",
    "        return f'{self.__class__} {self.name}'\n",
    "    \n",
    "    def add_from_df(self, values:pd.DataFrame, repeatCol=-1, deduplicate_by:List=[]):\n",
    "        df = self.Pattern.make_records(values, repeatCol=repeatCol)\n",
    "        if deduplicate_by:\n",
    "            self.remove({k:v for k, v in df.drop_duplicates().items() if k in deduplicate_by})\n",
    "        self.df = pd.concat([self.df, df]).reset_index(drop=True)\n",
    "        self.post_op()\n",
    "        \n",
    "    \n",
    "    def add(self, values:Dict, repeats:Union[int, Tuple, List, np.ndarray]=1, deduplicate_by:List=[]):\n",
    "        '''\n",
    "        If duplicated records are not allowed - such as in the case of knownspells, use the deduplicate_by parameter to find existing records having same values in these columns\n",
    "        remove those record before adding new ones\n",
    "        '''\n",
    "        values = self.Pattern.make_recordIndex_from_dict(values, repeats)\n",
    "        self.add_from_df(values, deduplicate_by=deduplicate_by)\n",
    "        \n",
    "        \n",
    "    def remove(self, values:Dict, remove_n:Optional[Union[int, Tuple, List, np.ndarray]]=None):\n",
    "        '''\n",
    "        Remove the first n records that matchs the values, if set to None, remove all\n",
    "        '''\n",
    "        iMap = self.Pattern.make_recordIndex_from_dict(values, remove_n)  # sequnces of cols are ensured to be aligned with Pattern segments in the called function\n",
    "        group = self.df.groupby(iMap.columns[:-1].tolist())\n",
    "        iMap = iMap.set_index([_ for _ in iMap.columns if _ != 'REPEATS']).to_dict()['REPEATS']\n",
    "        self.df = group.apply(lambda x: x.head(0 if iMap.get(x.name, 0) is None else max(0, x.shape[0] - iMap.get(x.name, 0)))).reset_index(drop=True)\n",
    "        self.post_op()\n",
    "        \n",
    "        \n",
    "    def assign(self, values:pd.DataFrame, repeatCol=-1):\n",
    "        self.df = self.Pattern.inverse_infer(self.Pattern.make_records(values, repeatCol=repeatCol))\n",
    "        self.post_op()\n",
    "        \n",
    "    \n",
    "    def post_op(self):\n",
    "        '''\n",
    "        Defines the actions after record df is modified, such as reset_index\n",
    "        '''\n",
    "        self.buffer = bytearray(b''.join(self.df.values.ravel()))\n",
    "        \n",
    "\n",
    "    def pack(self):\n",
    "        self.countValue = self.df.shape[0]\n",
    "        return super().pack()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "616803b2f19e1e9bcbf5ac8abb36b7fd12ef6319f5b436273684431f9aa2d3e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
