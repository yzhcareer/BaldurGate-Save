{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from enum import Enum\n",
    "import zipfile\n",
    "from typing import Optional, Union, List, Callable, Dict, Tuple\n",
    "from dataclasses import dataclass, make_dataclass, field\n",
    "from abc import ABC\n",
    "from importnb import Notebook\n",
    "\n",
    "PKG_ROOT = os.path.dirname(os.path.realpath(os.getcwd()))\n",
    "if not PKG_ROOT in sys.path:\n",
    "    sys.path.append(PKG_ROOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Notebook():\n",
    "    from src.basestructs import *\n",
    "    from src.baseblocks import *\n",
    "    from src.basesegs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Party(SegBlock):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.CREIndexLength, self.CREOffsetLoc, self.CRESizeLoc = self.get_CRE_locs()\n",
    "        self.parse_party()\n",
    "        \n",
    "    def get_CRE_locs(self):\n",
    "        loc_df = self.savRef.creLocs\n",
    "        CREIndexLen = self.to_int(loc_df[loc_df['SubSegs']=='Header']['SizeValue'].iloc[0])\n",
    "        CREOffsetLoc, CRESizeLoc =  loc_df[loc_df['SubSegs']=='CRE'][['OffsetLoc', 'SizeLoc']].iloc[0].apply(self.to_int)\n",
    "        return CREIndexLen, CREOffsetLoc, CRESizeLoc\n",
    "    \n",
    "    def parse_party(self):\n",
    "        self.indexHeader = self.buffer[: self.CREIndexLength * self.countBlock.value]\n",
    "        self.CREOffsetBlocks = [ValueBlock(self.buffer, 'CREOFFSET', self.CREOffsetLoc + self.CREIndexLength * i, 4) for i in range(self.countBlock.value)]\n",
    "        self.CRESizeBlocks = [ValueBlock(self.buffer, 'CRESIZE', self.CRESizeLoc + self.CREIndexLength * i, 4) for i in range(self.countBlock.value)]\n",
    "        vRecords = self.savRef.creValues\n",
    "        tRecords = self.savRef.creTables\n",
    "        sRecords = self.savRef.creSegs\n",
    "        self.CRES = [CRE(self.savRef\n",
    "                        ,self\n",
    "                        ,self.pbuffer[o.value: o.value + s.value]\n",
    "                        ,vRecords\n",
    "                        ,tRecords\n",
    "                        ,sRecords\n",
    "                        ) for o, s in zip(self.CREOffsetBlocks, self.CRESizeBlocks)]\n",
    "        \n",
    "    def pack(self):\n",
    "        [_.pack() for _ in self.CRES]\n",
    "        self.buffer = bytearray(b''.join([self.indexHeader, *[_.buffer for _ in self.CRES]]))\n",
    "        self.sizeValue = len(self.buffer)\n",
    "        self.offsetValue = self.previous.offsetValue + self.previous.sizeValue\n",
    "        creSizes = np.array([_.size for _ in self.CRES])\n",
    "        creOffsets = np.concatenate([[0], creSizes]).cumsum()[:-1] + len(self.indexHeader) + self.offsetValue\n",
    "        for o, s, ob, sb in zip(creOffsets, creSizes, self.CREOffsetBlocks, self.CRESizeBlocks):\n",
    "            ob.bind_buffer(self.buffer).set_value(int(o))\n",
    "            sb.bind_buffer(self.buffer).set_value(int(s))\n",
    "        return self.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GamCreBase(ABC, BlockBase):\n",
    "    \n",
    "    SEGMAP = {\"KnownSpells\": KnownSpells\n",
    "             ,\"SpellMemorization\": SpellMemorization\n",
    "             ,\"MemorizedSpells\": MemorizedSpells\n",
    "             ,\"Effects\": Effects\n",
    "             ,\"Items\": Items\n",
    "             ,\"ItemSlots\": ItemSlots\n",
    "             ,\"Party\": Party\n",
    "             ,\"NPC\": Party\n",
    "             ,\"Global\": Globals}\n",
    "        \n",
    "        \n",
    "    def init_seg_size(self):\n",
    "        df = self.segRecords.copy()\n",
    "        df.insert(df.shape[1]\n",
    "                 ,'OffsetValue'\n",
    "                 ,self.segRecords['OffsetLoc'].apply(lambda x: np.nan if pd.isnull(x) else self.bytes2Num(self.buffer[self.to_int(x)\n",
    "                                                                                                                     :self.to_int(x)+4])))\n",
    "        df1 = df[df['OffsetValue']!=0].fillna(value={'OffsetValue': 0})\n",
    "        df2 = df[df['OffsetValue']==0]\n",
    "        df1['SizeValue'] = df1['OffsetValue'].shift(-1, fill_value=self.size) - df1['OffsetValue']\n",
    "        self.segRecords = pd.concat([df1, df2]).fillna(value={'SizeValue': 0}).sort_index()\n",
    "        \n",
    "    \n",
    "    def init_values(self, buffer:Optional[bytearray]=None): \n",
    "        self.VALUES = pd.Series([], dtype=object)\n",
    "        if not self.valueRecords.empty:\n",
    "            if buffer == None:\n",
    "                buffer = self.SEGS[0].buffer\n",
    "            self.VALUES = self.valueRecords.apply(lambda x: ValueBlock(buffer, *x), axis=1)\n",
    "            for i in range(self.VALUES.size):\n",
    "                setattr(self, self.VALUES[i].name, self.VALUES[i])\n",
    "            \n",
    "            # self.valueRecords.apply(lambda x: setattr(self, x[0], ValueBlock(buffer, *x[1:])),axis=1)\n",
    "            # self.VALUES = make_dataclass('VALUES', self.valueRecords.apply(lambda x: (x[0]\n",
    "            #                                                                          ,ValueBlock\n",
    "            #                                                                          ,ValueBlock(buffer, *x[1:]))\n",
    "            #                                                                ,axis=1))\n",
    "            \n",
    "            \n",
    "    def init_tables(self, buffer:Optional[bytearray]=None):\n",
    "        self.TABLEVALUES = pd.Series([], dtype=object)\n",
    "        if not self.tableRecords.empty:\n",
    "            if buffer == None:\n",
    "                buffer = self.buffer\n",
    "            self.TABLEVALUES = self.tableRecords.apply(lambda x: TableBlock(buffer, *x, getattr(self.savRef, x['RefTable'])) ,axis=1)\n",
    "            for i in range(self.TABLEVALUES.size):\n",
    "                setattr(self, self.TABLEVALUES[i].name, self.TABLEVALUES[i])\n",
    "            # self.TABLES = make_dataclass('TABLES', self.tableRecords.apply(lambda x: (x[0]\n",
    "            #                                                                          ,TableBlock\n",
    "            #                                                                          ,TableBlock(buffer\n",
    "            #                                                                                      ,*x[1:]\n",
    "            #                                                                                      ,getattr(self.savRef, x['RefTable'])))\n",
    "            #                                                                ,axis=1))\n",
    "                                                                           \n",
    "            \n",
    "    def init_segs(self, buffer:Optional[bytearray]=None):\n",
    "        '''\n",
    "        Need to keep sequence order\n",
    "        So use pd.Series instead of dataclass\n",
    "        '''\n",
    "        self.SEGS = pd.Series([], dtype=object)\n",
    "        if not self.segRecords.empty:\n",
    "            if buffer == None:\n",
    "                buffer = self.buffer\n",
    "            self.SEGS = (self.segRecords\n",
    "                         .set_index(self.segRecords.columns[0])\n",
    "                         .apply(lambda x: self.SEGMAP.get(x.name, SegBlock)(self.savRef, self, buffer, x.name, *x), axis=1))\n",
    "            for i in range(1, self.SEGS.size):\n",
    "                self.SEGS[i].previous = self.SEGS[i-1]\n",
    "                setattr(self, self.SEGS[i].name, self.SEGS[i])\n",
    "            \n",
    "            \n",
    "    def pack(self):\n",
    "        self.buffer = bytearray(b''.join([_.pack() for _ in self.SEGS]))\n",
    "        self.size = len(self.buffer)\n",
    "        for seg in self.SEGS:\n",
    "            seg.offsetBlock.bind_buffer(self.buffer).set_value(seg.offsetValue)\n",
    "            seg.countBlock.bind_buffer(self.buffer).set_value(seg.countValue)\n",
    "            seg.sizeBlock.bind_buffer(self.buffer).set_value(seg.sizeValue)\n",
    "        return self.buffer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRE(GamCreBase):\n",
    "    \n",
    "    def __init__(self\n",
    "                ,savRef:object\n",
    "                ,parentRef:object\n",
    "                ,buffer: bytearray\n",
    "                ,valueRecords: Optional[pd.DataFrame] = None\n",
    "                ,tableRecords: Optional[pd.DataFrame] = None\n",
    "                ,segRecords: Optional[pd.DataFrame] = None\n",
    "                ):\n",
    "        self.savRef = savRef\n",
    "        self.parentRef = parentRef\n",
    "        self.buffer = buffer\n",
    "        self.size = len(self.buffer)\n",
    "        if valueRecords is None:\n",
    "            self.valueRecords = pd.read_csv(os.path.join(self.savRef.resourceDir, 'CREVALUES.csv'), index_col=0)\n",
    "        else:\n",
    "            self.valueRecords = valueRecords.copy()\n",
    "        if tableRecords is None:\n",
    "            self.tableRecords = pd.read_csv(os.path.join(self.savRef.resourceDir, 'CRETABLES.csv'), index_col=0)\n",
    "        else:\n",
    "            self.tableRecords = tableRecords.copy()\n",
    "        if segRecords is None:\n",
    "            self.segRecords = pd.read_csv(os.path.join(self.savRef.resourceDir, 'CRESEGS.csv'), index_col=0)\n",
    "        else:\n",
    "            self.segRecords = segRecords.copy()\n",
    "        self.VALUES = make_dataclass('SEGS', [])\n",
    "        self.TABLES = make_dataclass('SEGS', [])\n",
    "        self.SEGS = pd.Series([], dtype=object)\n",
    "        self.init_seg_size()\n",
    "        self.init_segs() \n",
    "        self.init_values()\n",
    "        self.init_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAM(GamCreBase):\n",
    "    \n",
    "    def __init__(self\n",
    "                 ,savRef: object\n",
    "                 ,buffer: bytearray):\n",
    "        self.savRef = savRef\n",
    "        self.resourceDir = savRef.resourceDir\n",
    "        self.buffer = buffer\n",
    "        self.size = len(self.buffer)\n",
    "        self.valueRecords = savRef.gamValues\n",
    "        self.segRecords = savRef.gamSegs\n",
    "        self.VALUES = make_dataclass('SEGS', [])\n",
    "        self.SEGS = pd.Series([], dtype=object)\n",
    "        self.init_seg_size()\n",
    "        self.init_segs()\n",
    "        self.init_values()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sav(GamCreBase):\n",
    "    \n",
    "    def __init__(self, savefile:str, game:str='BGEE'):   # for other games, RACE, KIT, STATES, CLASS may need to copy from BGEE since the list is more comprehensive\n",
    "        self.savefile = os.path.join(PKG_ROOT, 'saves', 'original', savefile)\n",
    "        self.modified = os.path.join(PKG_ROOT, 'saves', 'modified', 'Edited_'+savefile)\n",
    "        self.resourceDir = os.path.join(PKG_ROOT, 'resources', game)\n",
    "        self.zipfile = zipfile.ZipFile(self.savefile)\n",
    "        self.filelist = self.zipfile.namelist()\n",
    "        self.files = [self.zipfile.read(_) for _ in self.filelist]\n",
    "        self.gamStr = self.files[1].decode('latin')\n",
    "        self.gamBuffer = bytearray(self.files[1])\n",
    "        self.gamVersion = re.findall(r'GAME\\s*V\\d+\\.\\d+', self.gamStr)[0]  #always 'GAMEV2.0'\n",
    "        self.creVersion = re.findall(r'CRE\\s*V\\d+\\.\\d+', self.gamStr)[0]  #always 'CRE V1.0'\n",
    "        self.load_dfs()\n",
    "        self.make_names()\n",
    "        self.GAM = GAM(savRef=self, buffer=self.gamBuffer)\n",
    "        self.Party = self.GAM.SEGS.Party.CRES\n",
    "        self.NPC = self.GAM.SEGS.NPC.CRES\n",
    "        \n",
    "        \n",
    "    def load_dfs(self):\n",
    "        self.gamValues = pd.read_csv(os.path.join(self.resourceDir, 'GAMVALUES.csv'), index_col=0)\n",
    "        self.gamSegs = pd.read_csv(os.path.join(self.resourceDir, 'GAMSEGS.csv'), index_col=0)\n",
    "        self.creValues = pd.read_csv(os.path.join(self.resourceDir, 'CREVALUES.csv'), index_col=0)\n",
    "        self.creTables = pd.read_csv(os.path.join(self.resourceDir, 'CRETABLES.csv'), index_col=0)\n",
    "        self.creSegs = pd.read_csv(os.path.join(self.resourceDir, 'CRESEGS.csv'), index_col=0)\n",
    "        self.creLocs = pd.read_csv(os.path.join(self.resourceDir, 'CRELOC.csv'), index_col=0)\n",
    "    \n",
    "    def make_names(self):\n",
    "        for itm in ['ITEM', 'SPELL', 'EFFECT']:\n",
    "            f = pd.read_csv(os.path.join(self.resourceDir, itm + '.csv'), index_col=0)\n",
    "            setattr(self, itm+'CODES', IDS.make_names(itm+'CODES', f))\n",
    "            setattr(self, itm, IDS.make_enum(itm, f, nameCol=-1, valueCol=-2))\n",
    "            if itm == 'ITEM':\n",
    "                setattr(self, itm+'CONTAINER', IDS.make_enum(itm+'CONTAINER', f[['ItemSlot', 'Item']]))\n",
    "            #setattr(self, itm, IDS.make_enum(itm, IDS.clean_duplicates(f), nameCol=-1, valueCol=-2))\n",
    "        for itm in ['WEAPON', *self.creTables['RefTable'].drop_duplicates()]: #Race, Kit, Class, Gender, Alignment\n",
    "            setattr(self, itm, IDS.make_enum(itm, pd.read_csv(os.path.join(self.resourceDir, itm + '.csv'), index_col=0)))\n",
    "        for itm in ['PARTYSLOTS', 'NPCSLOTS']:\n",
    "            f = pd.read_csv(os.path.join(self.resourceDir, itm + '.csv'), index_col=0)\n",
    "            f = f.groupby(f.columns[0]).apply(lambda x: x.index.to_list()).to_frame().reset_index()\n",
    "            setattr(self, itm, IDS.make_enum(itm, f, nameCol=0))\n",
    "               \n",
    "            \n",
    "    def pack(self, filename:str=None):\n",
    "        if filename is None:\n",
    "            filename = self.modified\n",
    "        self.zipfile.close()\n",
    "        with zipfile.ZipFile(filename, 'w') as target:\n",
    "            target.writestr(self.filelist[0], self.files[0], compress_type=zipfile.ZIP_STORED)\n",
    "            target.writestr(self.filelist[1], self.GAM.pack(), compress_type=zipfile.ZIP_STORED)\n",
    "            for _name, _f in zip(self.filelist[2:], self.files[2:]):\n",
    "                target.writestr(_name, _f, compress_type=zipfile.ZIP_STORED)\n",
    "                \n",
    "                \n",
    "    def optimize(self):\n",
    "        [_.set_value(_.optimize) for _ in self.GAM.VALUES]\n",
    "        [_.set_value(_.optimize) for c in self.Party for _ in c.VALUES]\n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "616803b2f19e1e9bcbf5ac8abb36b7fd12ef6319f5b436273684431f9aa2d3e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
